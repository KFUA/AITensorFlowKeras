{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow卷积神经网络识别手写数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow多元感知器模型识别MNIST数据集中的手写数字，准确率可以为96%（设置隐藏层神经元个数为1000，并设置两个隐藏层）。使用CNN来识别MNIST数据集中的手写数字，其分类精度接近99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tensorFlow\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c1f8b53ada32>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Python\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Python\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Python\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Python\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Python\\envs\\tensorFlow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\",one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 建立共享函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义weight函数，用于建立权重张量\n",
    "def weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.1),name='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义bias函数，用于建立偏差张量\n",
    "def bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1,shape=shape),name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义conv2d函数，用于进行卷积运算\n",
    "#x:输入的图像，必须是四维张量\n",
    "#W:滤镜权重，会以随机方式产生\n",
    "#strides:滤镜的步长，设置为[1,1,1,1],其格式为[1,stride,stride,1],也就是滤镜每次移动时，从左到右，从上到下各一步\n",
    "#padding:设置为‘SAME’模式，即在边界之外补零，使输入与输出的图像大小相同\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立max_pool_2x2函数，用于建立池化层\n",
    "def max_pool_2x2(x):\n",
    "    #ksize为缩减窗口的大小，设置为[1,2,2,1],其格式为[1,height,width,1],即为高度=2、宽度=2的窗口\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],  \n",
    "                         strides=[1,2,2,1],\n",
    "                         padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立输入层\n",
    "with tf.name_scope('Input_Layer'):\n",
    "    x = tf.placeholder(\"float\",shape=[None,784],name=\"x\")\n",
    "    #x原本为一维张量，因后续需要进行卷积与池化运算，所以必须转换为四维张量\n",
    "    #第一维-1：表示训练时通过placehodel输入的项数不固定，所以设置为-1\n",
    "    #第二，三维是28，28：即图像的大小为28x28。\n",
    "    #第四维是1：代表为单色，故设置为1。若为彩色则设置为3。\n",
    "    x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立卷积层1\n",
    "with tf.name_scope('C1_Conv'):\n",
    "    #第一、二维均为5代表滤镜（filter weight）的大小5x5\n",
    "    #第三维是1：代表单色，如果是彩色需要设置为3\n",
    "    #第四维是16：表示产生16个图像\n",
    "    W1 = weight([5,5,1,16])\n",
    "    b1 = bias([16])\n",
    "    Conv1 = conv2d(x_image,W1) + b1\n",
    "    #卷积运算的结果再由ReLU激活函数转换，最后的结果为C1_Conv\n",
    "    C1_Conv = tf.nn.relu(Conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立池化层1\n",
    "with tf.name_scope('C1_pool'):\n",
    "    C1_pool = max_pool_2x2(C1_Conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立卷积层2\n",
    "with tf.name_scope('C2_Conv'):\n",
    "    W2 = weight([5,5,16,36])\n",
    "    b2 = bias([36])\n",
    "    Conv2 = conv2d(C1_pool,W2)+b2\n",
    "    C2_Conv = tf.nn.relu(Conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立池化层2\n",
    "with tf.name_scope('C2_Pool'):\n",
    "    C2_Pool = max_pool_2x2(C2_Conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立平坦层\n",
    "with tf.name_scope('D_Flat'):\n",
    "    #-1表示传入不限定项数的训练数据，1764=36x7x7\n",
    "    D_Flat = tf.reshape(C2_Pool,[-1,1764])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立隐藏层\n",
    "with tf.name_scope('D_Hidden_Layer'):\n",
    "    W3 = weight([1764,128])\n",
    "    b3 = bias([128])\n",
    "    D_Hidden = tf.nn.relu(\n",
    "                  #D_Flat相乘再加上偏差向量\n",
    "                  tf.matmul(D_Flat,W3)+b3)\n",
    "    #加入Dropout避免过度拟合，0.8代表要保留80%的神经元。随机去掉20%的神经元\n",
    "    D_Hidden_Dropout = tf.nn.dropout(D_Hidden,keep_prob=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立输出层\n",
    "with tf.name_scope('Output_layer'):\n",
    "    W4 = weight([128,10])\n",
    "    b4 = bias([10])\n",
    "    y_predict = tf.nn.softmax(\n",
    "                   tf.matmul(D_Hidden_Dropout,W4)+b4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 定义训练方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-57839321313d>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    #建立训练数据label真实值的placeholder\n",
    "    y_label = tf.placeholder(\"float\",shape=[None,10],\n",
    "                             name=\"y_label\")\n",
    "    loss_function = tf.reduce_mean(\n",
    "                     tf.nn.softmax_cross_entropy_with_logits(\n",
    "                         logits=y_predict,labels=y_label))\n",
    "    #定义优化器\n",
    "    #调用tf.train模块定义optimizer（优化器）\n",
    "    #使用AdamOptimizer并设置learning_rate=0.001\n",
    "    #优化器使用loss_function计算误差，并且按照误差更新模型权重与偏差，是误差最小化\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss_function)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 定义评估模型准确率的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"evaluate_model\"):\n",
    "    #计算每一项数据是否预测正确\n",
    "    #tf.equal判断真实值与预测值是否相等，相等返回1，不相等返回0\n",
    "    #tf.argmax将One-Hot Encoding转换为数字0~9\n",
    "    correct_prediction = tf.equal(tf.argmax(y_predict,1),\n",
    "                                 tf.argmax(y_label,1))\n",
    "    #计算预测正确结果的平均值\n",
    "    #tf.cast将correct_prediction转换为“float”\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义训练参数\n",
    "trainEpochs = 30  #执行30个训练周期，尽量使误差降低，并且尽可能提高准确率\n",
    "batchSize = 100\n",
    "totalBatchs = int(mnist.train.num_examples/batchSize)\n",
    "loss_list=[];epoch_list=[];accuracy_list=[]\n",
    "from time import time\n",
    "startTime=time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 01 Loss= 1.675215244 Accuracy= 0.812\n",
      "Train Epoch: 02 Loss= 1.626377225 Accuracy= 0.8434\n",
      "Train Epoch: 03 Loss= 1.611052871 Accuracy= 0.8576\n",
      "Train Epoch: 04 Loss= 1.602253675 Accuracy= 0.8652\n",
      "Train Epoch: 05 Loss= 1.594627738 Accuracy= 0.8698\n",
      "Train Epoch: 06 Loss= 1.522397995 Accuracy= 0.947\n",
      "Train Epoch: 07 Loss= 1.503340006 Accuracy= 0.9624\n",
      "Train Epoch: 08 Loss= 1.498921037 Accuracy= 0.967\n",
      "Train Epoch: 09 Loss= 1.493156433 Accuracy= 0.971\n",
      "Train Epoch: 10 Loss= 1.490795851 Accuracy= 0.9732\n",
      "Train Epoch: 11 Loss= 1.488277912 Accuracy= 0.9768\n",
      "Train Epoch: 12 Loss= 1.488481045 Accuracy= 0.975\n",
      "Train Epoch: 13 Loss= 1.485585570 Accuracy= 0.9784\n",
      "Train Epoch: 14 Loss= 1.486248493 Accuracy= 0.9776\n",
      "Train Epoch: 15 Loss= 1.483244181 Accuracy= 0.9794\n",
      "Train Epoch: 16 Loss= 1.482164025 Accuracy= 0.9804\n",
      "Train Epoch: 17 Loss= 1.482625008 Accuracy= 0.9798\n",
      "Train Epoch: 18 Loss= 1.480748415 Accuracy= 0.9808\n",
      "Train Epoch: 19 Loss= 1.480840087 Accuracy= 0.9822\n",
      "Train Epoch: 20 Loss= 1.479578614 Accuracy= 0.9826\n",
      "Train Epoch: 21 Loss= 1.480061769 Accuracy= 0.9834\n",
      "Train Epoch: 22 Loss= 1.480479002 Accuracy= 0.9818\n",
      "Train Epoch: 23 Loss= 1.478796244 Accuracy= 0.9834\n",
      "Train Epoch: 24 Loss= 1.479332089 Accuracy= 0.9828\n",
      "Train Epoch: 25 Loss= 1.477596283 Accuracy= 0.9844\n",
      "Train Epoch: 26 Loss= 1.478822470 Accuracy= 0.9822\n",
      "Train Epoch: 27 Loss= 1.477337360 Accuracy= 0.984\n",
      "Train Epoch: 28 Loss= 1.475537062 Accuracy= 0.987\n",
      "Train Epoch: 29 Loss= 1.476700306 Accuracy= 0.9866\n",
      "Train Epoch: 30 Loss= 1.475644827 Accuracy= 0.987\n",
      "Train Finished takes: 2522.8112156391144\n",
      "Accuracy: 0.9857\n",
      "prediction_result[:10]: [7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #进行训练\n",
    "    for epoch in range(trainEpochs):           #执行30个训练周期\n",
    "        for i in range(totalBatchs):           #执行550批次训练：使用优化器进行训练，使误差最小化\n",
    "            batch_x,batch_y = mnist.train.next_batch(batchSize)  #每批次读取100项数据\n",
    "            #执行批次训练\n",
    "            sess.run(optimizer,feed_dict={x:batch_x,\n",
    "                                     y_label:batch_y})\n",
    "        #使用验证数据计算准确率\n",
    "        loss,acc = sess.run([loss_function,accuracy],feed_dict={x:mnist.validation.images,\n",
    "                                                               y_label:mnist.validation.labels})\n",
    "        #显示训练结果，并存入列表用于后续显示图表\n",
    "        epoch_list.append(epoch);\n",
    "        loss_list.append(loss)\n",
    "        accuracy_list.append(acc)\n",
    "        print(\"Train Epoch:\",'%02d'%(epoch+1),\"Loss=\",\"{:.9f}\".format(loss),\"Accuracy=\",acc)\n",
    "    #显示全部运行时间\n",
    "    duration = time()-startTime\n",
    "    print(\"Train Finished takes:\",duration) \n",
    "    #评估模型准确率\n",
    "    print(\"Accuracy:\",sess.run(accuracy,feed_dict={x:mnist.test.images,\n",
    "                                                  y_label:mnist.test.labels}))\n",
    "    #进行预测\n",
    "    prediction_result = sess.run(tf.argmax(y_predict,1),\n",
    "                                feed_dict={x:mnist.test.images})\n",
    "    #预测结果\n",
    "    print(\"prediction_result[:10]:\",prediction_result[:10])\n",
    "    #TensorBoard\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter('log/CNN',sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "查看“计算图”的命令：tensorboard --logdir=E:\\pythonwork\\log\\CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在浏览器中输入：http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
