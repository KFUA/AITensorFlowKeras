{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras建立MLP、RNN、LSTM模型进行IMDb情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 建立MLP模型进行IMDb情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\tensorFlow\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#导入模块\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取IMDb数据\n",
    "#创建rm_tag函数删除文字中的HTML标签\n",
    "import re                                  #导入Regular Expression模块\n",
    "def rm_tags(text):                        #创建rm_tags函数，输入参数text文字\n",
    "    re_tag = re.compile(r'<[^>]+>')        #创建re_tag为正则表达式变量\n",
    "    return re_tag.sub('',text)             #将text文字中符合正则表达式条件的字符替换成空字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#创建read_files函数读取IMDb文件目录\n",
    "import os\n",
    "def read_files(filetype):           #读取训练数据时传入“train”;读取测试数据时传入“test”\n",
    "    path = \"data/aclImdb/\"\n",
    "    file_list=[]\n",
    "    \n",
    "    positive_path=path+filetype+\"/pos/\"        #设置正面评价的文件目录\n",
    "    for f in os.listdir( positive_path):      #for循环将positive_path目录下所有的文件加入file_list\n",
    "        file_list+=[ positive_path+f]\n",
    "    \n",
    "    negative_path=path+filetype+\"/neg/\"        #设置负面评价的文件目录\n",
    "    for f in os.listdir( negative_path):      #for循环将negative_path目录下所有的文件加入file_list\n",
    "        file_list+=[ negative_path+f]\n",
    "    \n",
    "    print('read',filetype,'files:',len(file_list))   #显示当前读取的filetype(\"train\"或“test”)目录下的文件个数\n",
    "    \n",
    "    all_labels = ([1]*12500+[0]*12500)   #前12500项是正面，产生12500项1的列表；后12500项是负面，产生12500项0的列表。\n",
    "    \n",
    "    all_texts = []\n",
    "    for fi in file_list:                #读取所有文件\n",
    "        with open(fi,encoding='utf8') as file_input:         #打开文件\n",
    "#使用file_input.readlines()读取文件，并使用join连接所有文件的内容，然后使用rm_tags删除tag,最后加入all_texts list\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "    return all_labels,all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 25000\n"
     ]
    }
   ],
   "source": [
    "#读取训练数据\n",
    "y_train,train_text=read_files(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test files: 25000\n"
     ]
    }
   ],
   "source": [
    "#读取测试数据\n",
    "y_test,test_text=read_files(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立token\n",
    "token = Tokenizer(num_words=2000)\n",
    "token.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将“影评文字”转换成“数字列表”\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#截长补短让所有“数字列表”的长度都为100\n",
    "x_train = sequence.pad_sequences(x_train_seq,maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test_seq,maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 加入嵌入层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras提供了嵌入层可以将“数字列表”转换为“向量列表”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立模型\n",
    "modelMPL = Sequential()\n",
    "#将“嵌入层”加入模型\n",
    "modelMPL.add(Embedding(output_dim=32,   #输出的维数为32，将“数字列表”转换为32维的向量\n",
    "                      input_dim=2000,   #输入的维数是2000，建立的字典有2000个单词\n",
    "                      input_length=100))  #“数值列表”每一项有100个数字\n",
    "#加入Dropout以避免过拟合\n",
    "modelMPL.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 建立MLP模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将“平坦层”加入模型\n",
    "modelMPL.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将“隐藏层”加入模型\n",
    "modelMPL.add(Dense(units=256,            #隐藏层共有256个单元\n",
    "                   activation='relu'))     #定义激活函数ReLU\n",
    "modelMPL.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将“输出层”加入模型\n",
    "modelMPL.add(Dense(units=1,                 #输出层只有1个神经元，输出1代表正面评价，0代表负面评价\n",
    "                  activation='sigmoid'))    #定义激活函数sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 883,713\n",
      "Trainable params: 883,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelMPL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义训练方式\n",
    "modelMPL.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 0.4905 - acc: 0.7488 - val_loss: 0.4572 - val_acc: 0.7886\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.2709 - acc: 0.8884 - val_loss: 0.6275 - val_acc: 0.7236\n",
      "Epoch 3/10\n",
      " - 8s - loss: 0.1641 - acc: 0.9378 - val_loss: 0.6444 - val_acc: 0.7498\n",
      "Epoch 4/10\n",
      " - 8s - loss: 0.0859 - acc: 0.9714 - val_loss: 0.7551 - val_acc: 0.7702\n",
      "Epoch 5/10\n",
      " - 8s - loss: 0.0486 - acc: 0.9836 - val_loss: 1.1073 - val_acc: 0.7300\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.0362 - acc: 0.9869 - val_loss: 1.0342 - val_acc: 0.7706\n",
      "Epoch 7/10\n",
      " - 8s - loss: 0.0305 - acc: 0.9893 - val_loss: 1.2062 - val_acc: 0.7426\n",
      "Epoch 8/10\n",
      " - 8s - loss: 0.0262 - acc: 0.9902 - val_loss: 1.1010 - val_acc: 0.7816\n",
      "Epoch 9/10\n",
      " - 9s - loss: 0.0248 - acc: 0.9908 - val_loss: 1.2973 - val_acc: 0.7578\n",
      "Epoch 10/10\n",
      " - 8s - loss: 0.0233 - acc: 0.9914 - val_loss: 1.5052 - val_acc: 0.7320\n"
     ]
    }
   ],
   "source": [
    "train_history = modelMPL.fit(x_train,y_train,batch_size=100,\n",
    "                            epochs=10,verbose=2,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 评估模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 75us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.808"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = modelMPL.evaluate(x_test,y_test,verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#执行预测\n",
    "predict=modelMPL.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预测结果\n",
    "predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用一维数组查看预测结果\n",
    "predict_classes=predict.reshape(-1)\n",
    "predict_classes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 查看测试数据预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前的预测结果是0与1，创建display_test_Sentiment函数，可以显示负面评价或正面评价。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#创建display_test_Sentiment函数。\n",
    "SentimentDict={1:'正面的',0:'负面的'}\n",
    "def display_test_Sentiment(i):\n",
    "    print(test_text[i])\n",
    "    print('label真实值：',SentimentDict[y_test[i]],\n",
    "         '预测结果：',SentimentDict[predict_classes[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw this film in a sneak preview, and it is delightful. The cinematography is unusually creative, the acting is good, and the story is fabulous. If this movie does not do well, it won't be because it doesn't deserve to. Before this film, I didn't realize how charming Shia Lebouf could be. He does a marvelous, self-contained, job as the lead. There's something incredibly sweet about him, and it makes the movie even better. The other actors do a good job as well, and the film contains moments of really high suspense, more than one might expect from a movie about golf. Sports movies are a dime a dozen, but this one stands out. This is one I'd recommend to anyone.\n",
      "label真实值： 正面的 预测结果： 正面的\n"
     ]
    }
   ],
   "source": [
    "#显示第3项数据\n",
    "display_test_Sentiment(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First of all I hate those moronic rappers, who could'nt act if they had a gun pressed against their foreheads. All they do is curse and shoot each other and acting like cliché'e version of gangsters.The movie doesn't take more than five minutes to explain what is going on before we're already at the warehouse There is not a single sympathetic character in this movie, except for the homeless guy, who is also the only one with half a brain.Bill Paxton and William Sadler are both hill billies and Sadlers character is just as much a villain as the gangsters. I did'nt like him right from the start.The movie is filled with pointless violence and Walter Hills specialty: people falling through windows with glass flying everywhere. There is pretty much no plot and it is a big problem when you root for no-one. Everybody dies, except from Paxton and the homeless guy and everybody get what they deserve.The only two black people that can act is the homeless guy and the junkie but they're actors by profession, not annoying ugly brain dead rappers.Stay away from this crap and watch 48 hours 1 and 2 instead. At lest they have characters you care about, a sense of humor and nothing but real actors in the cast.\n",
      "label真实值： 负面的 预测结果： 负面的\n"
     ]
    }
   ],
   "source": [
    "#显示第12502项数据\n",
    "display_test_Sentiment(12502)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 查看《美女与野兽》的影评"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前的预测使用的是IMDb数据集的影评文字，接下来使用热门电影《美女与野兽》的影评文字进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《美女与野兽》影评查看网址：http://www.imdb.com/title/tt2771200/reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text=''' I have re-watched this in theaters this weekend, so I come fresh with this movie in mind. Having said that, my perception of this movie has not changed. I will also add that this story was my favorite Disney story growing up. Having watched it twice now, my experience has remained the same. I still got lost in the story, the imagery, the music, and the singing. The plot was almost completely the same as that of the cartoon version, with a few additions. I very much loved these new additions as they added depth to the story and closed some plot holes. It also helped to better establish the relationship between Belle and the Beast.P.S. Loved the gay millisecond! I don't know what all the fuss was about. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#转换成“数字列表”\n",
    "input_seq = token.texts_to_sequences([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 24, 791, 292, 10, 7, 10, 34, 9, 212, 1472, 15, 10, 16, 7, 326, 256, 296, 11, 57, 4, 10, 16, 43, 20, 1189, 9, 76, 77, 758, 11, 10, 61, 12, 57, 510, 909, 61, 1789, 52, 256, 292, 8, 1447, 146, 57, 581, 43, 1, 168, 9, 127, 184, 412, 7, 1, 61, 1, 1, 224, 2, 1, 1115, 1, 110, 12, 216, 336, 1, 168, 13, 11, 4, 1, 1068, 306, 15, 3, 167, 9, 51, 72, 443, 130, 157, 13, 32, 1280, 1133, 5, 1, 61, 2, 45, 110, 1507, 8, 77, 1668, 5, 124, 1, 644, 196, 2, 1, 1683, 586, 443, 1, 987, 9, 88, 120, 47, 28, 1, 12, 40]\n"
     ]
    }
   ],
   "source": [
    "print(input_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#截取“数字列表”使其长度为100\n",
    "pad_input_seq = sequence.pad_sequences(input_seq,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pad_input_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用多层感知器进行预测\n",
    "predict_result=modelMPL.predict_classes(pad_input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看预测结果\n",
    "predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取预测结果中的元素\n",
    "predict_result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'正面的'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentimentDict[predict_result[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 使用较大字典提高准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "建立字典的单词数：原本为1000个单词的字典，增加为建立有3800个单词的字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“数字列表”截长补短的长度：原本“数字列表”的长度都是100个数字，现在改为380个数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取所有文章建立字典，限制字典单词数为3800\n",
    "tokenLage = Tokenizer(num_words=3800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenLage.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将文字转为数字序列\n",
    "xLage_train_seq = tokenLage.texts_to_sequences(train_text)\n",
    "xLage_test_seq = tokenLage.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#截长补短，让所有影评所产生的数字序列长度一样\n",
    "xLage_train=sequence.pad_sequences(xLage_train_seq,maxlen=380)\n",
    "xLage_test=sequence.pad_sequences(xLage_test_seq,maxlen=380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLage = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLage.add(Embedding(output_dim=32,\n",
    "                       input_dim=3800,\n",
    "                       input_length=380))\n",
    "modelLage.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLage.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLage.add(Dense(units=256,\n",
    "                   activation='relu'))\n",
    "modelLage.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLage.add(Dense(units=1,\n",
    "                   activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12160)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               3113216   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,235,073\n",
      "Trainable params: 3,235,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelLage.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#整理为函数\n",
    "padLage_input_seq=sequence.pad_sequences(input_seq,maxlen=380)\n",
    "def predictLage_review(input_text):\n",
    "    input_seq=tokenLage.texts_to_sequences({input_text})\n",
    "    padLage_input_seq = sequence.pad_sequences(input_seq,maxlen=380)\n",
    "    predictLage_result = modelLage.predict_classes(padLage_input_seq)\n",
    "    print(SentimentDict[predictLage_result[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定义训练方式\n",
    "modelLage.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 26s - loss: 0.4704 - acc: 0.7624 - val_loss: 0.4493 - val_acc: 0.8086\n",
      "Epoch 2/10\n",
      " - 27s - loss: 0.1868 - acc: 0.9289 - val_loss: 0.6750 - val_acc: 0.7314\n",
      "Epoch 3/10\n",
      " - 28s - loss: 0.0668 - acc: 0.9783 - val_loss: 0.7776 - val_acc: 0.7736\n",
      "Epoch 4/10\n",
      " - 26s - loss: 0.0265 - acc: 0.9922 - val_loss: 1.0905 - val_acc: 0.7346\n",
      "Epoch 5/10\n",
      " - 25s - loss: 0.0161 - acc: 0.9952 - val_loss: 1.2954 - val_acc: 0.7354\n",
      "Epoch 6/10\n",
      " - 25s - loss: 0.0147 - acc: 0.9955 - val_loss: 1.1779 - val_acc: 0.7662\n",
      "Epoch 7/10\n",
      " - 26s - loss: 0.0160 - acc: 0.9942 - val_loss: 1.0140 - val_acc: 0.7846\n",
      "Epoch 8/10\n",
      " - 26s - loss: 0.0163 - acc: 0.9942 - val_loss: 1.2774 - val_acc: 0.7626\n",
      "Epoch 9/10\n",
      " - 25s - loss: 0.0162 - acc: 0.9944 - val_loss: 1.1075 - val_acc: 0.8016\n",
      "Epoch 10/10\n",
      " - 25s - loss: 0.0144 - acc: 0.9950 - val_loss: 1.1448 - val_acc: 0.8116\n"
     ]
    }
   ],
   "source": [
    "trainLage_history = modelLage.fit(xLage_train,y_train,batch_size=100,\n",
    "                            epochs=10,verbose=2,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 6s 222us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85072"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#评估模型准确率\n",
    "scores = modelLage.evaluate(xLage_test,y_test,verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由以上结果可知，字典数增加为3800，并且“数字列表”的长度增加为380。训练时间变长，但是准确率有所提高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 建立RNN模型进行IMDb情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么使用RNN模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST数据集（识别数字图形）、Cifar数据集（识别照片）图像并不会随着时间而改变，所以使用MPL或CNN都具有较好的效果。而人工智能所要解决的问题很多是顺序性的，例如自然语言处理（同一时间只能听到一个字，之前的语言会影响之后语言的含义）、视频图像处理（视频是一张张照片，依照时间顺序组成）、气象观测数据（信息随时间不断改变）和股票交易数据（股市开盘后，股价随着时间不断变动）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP或CNN都只能依照当前的状态进行识别，如果要处理时间序列的问题，就必须使用RNN与LSTM模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN模型的原理是将神经元的输出再接回神经元的输入。这样的设计使神经网络具备“记忆”功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelRNN = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将“嵌入层”加入模型\n",
    "modelRNN.add(Embedding(output_dim=32,   #输出的维数为32，将“数字列表”转换为32维的向量\n",
    "                      input_dim=2000,   #输入的维数是2000，建立的字典有2000个单词\n",
    "                      input_length=100))  #“数值列表”每一项有100个数字\n",
    "#加入Dropout以避免过拟合\n",
    "modelRNN.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RNN层\n",
    "modelRNN.add(SimpleRNN(units=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelRNN.add(Dense(units=256,activation='relu'))\n",
    "modelRNN.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelRNN.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 69,393\n",
      "Trainable params: 69,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 7s - loss: 0.5349 - acc: 0.7331 - val_loss: 0.5267 - val_acc: 0.7564\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.3646 - acc: 0.8437 - val_loss: 0.6378 - val_acc: 0.7280\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.3166 - acc: 0.8696 - val_loss: 0.4076 - val_acc: 0.8226\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.2794 - acc: 0.8854 - val_loss: 0.3549 - val_acc: 0.8604\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.2469 - acc: 0.9006 - val_loss: 0.6791 - val_acc: 0.7198\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.2125 - acc: 0.9163 - val_loss: 0.5516 - val_acc: 0.7864\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.1866 - acc: 0.9274 - val_loss: 0.6771 - val_acc: 0.7564\n",
      "Epoch 8/10\n",
      " - 6s - loss: 0.1569 - acc: 0.9387 - val_loss: 0.6065 - val_acc: 0.7984\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.1349 - acc: 0.9480 - val_loss: 0.8218 - val_acc: 0.7720\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.1110 - acc: 0.9590 - val_loss: 1.4831 - val_acc: 0.6412\n"
     ]
    }
   ],
   "source": [
    "#定义训练方式\n",
    "modelRNN.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "trainRNN_history = modelRNN.fit(x_train,y_train,batch_size=100,\n",
    "                            epochs=10,verbose=2,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 4s 180us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77768"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = modelRNN.evaluate(x_test,y_test,verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 建立LSTM模型进行IMDb情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "长短期记忆（Long Short Term Memory,LSTM）也是一种时间递归神经网络，专门设计用来解决RNN的长期依赖问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "长期依赖问题就是在每一个时间的间隔不断增大时，RNN会丧失学习到连接到远处的信息的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单的说，RNN只有短期的记忆，没有长期的记忆。在LSTM神经网络中，每一个神经元相当于一个记忆细胞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLSTM = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将“嵌入层”加入模型\n",
    "modelLSTM.add(Embedding(output_dim=32,   #输出的维数为32，将“数字列表”转换为32维的向量\n",
    "                      input_dim=2000,   #输入的维数是2000，建立的字典有2000个单词\n",
    "                      input_length=100))  #“数值列表”每一项有100个数字\n",
    "#加入Dropout以避免过拟合\n",
    "modelLSTM.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSTM层\n",
    "modelLSTM.add(LSTM(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLSTM.add(Dense(units=256,activation='relu'))\n",
    "modelLSTM.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLSTM.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 146,817\n",
      "Trainable params: 146,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 18s - loss: 0.4802 - acc: 0.7607 - val_loss: 0.4982 - val_acc: 0.7426\n",
      "Epoch 2/10\n",
      " - 15s - loss: 0.3300 - acc: 0.8612 - val_loss: 0.5539 - val_acc: 0.7070\n",
      "Epoch 3/10\n",
      " - 15s - loss: 0.3093 - acc: 0.8711 - val_loss: 0.3143 - val_acc: 0.8600\n",
      "Epoch 4/10\n",
      " - 15s - loss: 0.2860 - acc: 0.8829 - val_loss: 0.5366 - val_acc: 0.7394\n",
      "Epoch 5/10\n",
      " - 15s - loss: 0.2713 - acc: 0.8892 - val_loss: 0.5807 - val_acc: 0.7584\n",
      "Epoch 6/10\n",
      " - 15s - loss: 0.2606 - acc: 0.8919 - val_loss: 0.5601 - val_acc: 0.7782\n",
      "Epoch 7/10\n",
      " - 15s - loss: 0.2490 - acc: 0.9006 - val_loss: 0.4166 - val_acc: 0.8190\n",
      "Epoch 8/10\n",
      " - 15s - loss: 0.2374 - acc: 0.9029 - val_loss: 0.5222 - val_acc: 0.7658\n",
      "Epoch 9/10\n",
      " - 15s - loss: 0.2273 - acc: 0.9070 - val_loss: 0.5245 - val_acc: 0.7634\n",
      "Epoch 10/10\n",
      " - 15s - loss: 0.2211 - acc: 0.9120 - val_loss: 0.5138 - val_acc: 0.7946\n"
     ]
    }
   ],
   "source": [
    "#定义训练方式\n",
    "modelLSTM.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "trainLSTM_history = modelLSTM.fit(x_train,y_train,batch_size=100,\n",
    "                            epochs=10,verbose=2,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 9s 352us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83392"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = modelLSTM.evaluate(x_test,y_test,verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上述结果可知，LSTM模型的准确率较RNN模型有所提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
