{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以TensorFlow张量运算仿真神经网络的运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 以矩阵运算仿真神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出 = 激活函数（输入x权重+偏差）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[y1 y2] = activation( [x1 x2 x3]x[w11 w12\n",
    "                                  w21] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入TensorFlow模块\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_sigmoid():\n",
    "    X = tf.Variable([[0.4,0.2,0.4]])\n",
    "    W = tf.Variable([[-0.5,-0.2],\n",
    "                    [-0.3,0.4],\n",
    "                    [-0.5,0.2]])\n",
    "    b = tf.Variable([[0.1,0.2]])\n",
    "    XWb = tf.matmul(X,W)+b\n",
    "    y_relu=tf.nn.relu(tf.matmul(X,W)+b)                 #使用relu激活函数\n",
    "    y_sigmoid=tf.nn.sigmoid(tf.matmul(X,W)+b)           #使用sigmoid激活函数\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        print('XWb:');print(sess.run(XWb))\n",
    "        print('y_relu:');print(sess.run(y_relu))\n",
    "        print('y_sigmoid:');print(sess.run(y_sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y_relu:\n",
      "[[0.   0.28]]\n",
      "y_sigmoid:\n",
      "[[0.41095957 0.5695462 ]]\n"
     ]
    }
   ],
   "source": [
    "relu_sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu的特色是：小于0输出是0，大于0输出等于输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于深度学习模型，以反向传播算法进行训练时，训练前必须先“建立模型”，建立多层感知模型必须以随机数初始化模型的权重与偏差。TensorFlow提供tf.random_normal可以用来产生正态分布的随机数的矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_dis():\n",
    "    X = tf.Variable([[0.4,0.2,0.4]])\n",
    "    W = tf.Variable(tf.random_normal([3,2]))\n",
    "    b = tf.Variable(tf.random_normal([1,2]))\n",
    "    XWb = tf.matmul(X,W)+b\n",
    "    y_relu=tf.nn.relu(tf.matmul(X,W)+b)                 #使用relu激活函数\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        (b,W,y_relu) = sess.run((b,W,y_relu))           #执行一次sess.run取得3个TensorFlow变量\n",
    "        print('b:');print(b)\n",
    "        print('W:');print(W)\n",
    "        print('y_relu:');print(y_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-0.97734547  0.5086532 ]]\n",
      "W:\n",
      "[[ 0.316556    1.7016572 ]\n",
      " [-1.9309672   1.2214875 ]\n",
      " [-0.04145029 -0.78084785]]\n",
      "y_relu:\n",
      "[[0.        1.1212745]]\n"
     ]
    }
   ],
   "source": [
    "normal_dis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53228784  0.25847065  0.6145472   2.3748431  -0.8388968 ]\n"
     ]
    }
   ],
   "source": [
    "#正态分布的随机数展示\n",
    "ts_norm = tf.random_normal([1000])\n",
    "with tf.Session() as session:\n",
    "    norm_data = ts_norm.eval()\n",
    "print(norm_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae1ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(norm_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 以placeholder传入X值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#以placeholder传入1x3的数组 \n",
    "import numpy as np\n",
    "def placeholder_input_1x1():\n",
    "    W = tf.Variable(tf.random_normal([3,2]))\n",
    "    b = tf.Variable(tf.random_normal([1,2]))\n",
    "    #建立计算图时，定义placehoder X\n",
    "    #“float”表示数据类型为浮点数，[Note,3]表示矩阵的形状。第一维设置为None,表示传入的X项数不想。\n",
    "    #第二维是每一项的数字的个数，每一项有3个数字，所以设置为3\n",
    "    X = tf.placeholder(\"float\",[None,3])     \n",
    "    y = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        X_array = np.array([[0.4,0.2,0.4]])        #建立X_array\n",
    "        (_b,_W,_X,_y) = sess.run((b,W,X,y),feed_dict={X:X_array})\n",
    "        print('b:');print(_b)\n",
    "        print('W:');print(_W)\n",
    "        print('X:');print(_X)\n",
    "        print('y:');print(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-0.44156966 -0.25257966]]\n",
      "W:\n",
      "[[ 1.2209659  -0.8371656 ]\n",
      " [ 1.9725857   0.6605664 ]\n",
      " [-0.02733079 -0.48399118]]\n",
      "X:\n",
      "[[0.4 0.2 0.4]]\n",
      "y:\n",
      "[[0.43040153 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "placeholder_input_1x1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#以placeholder传入3x3的数组 \n",
    "def placeholder_input_3x3():\n",
    "    W = tf.Variable(tf.random_normal([3,2]))\n",
    "    b = tf.Variable(tf.random_normal([1,2]))\n",
    "    #建立计算图时，定义placehoder X\n",
    "    #“float”表示数据类型为浮点数，[Note,3]表示矩阵的形状。第一维设置为None,表示传入的X项数不想。\n",
    "    #第二维是每一项的数字的个数，每一项有3个数字，所以设置为3\n",
    "    X = tf.placeholder(\"float\",[None,3])     \n",
    "    y = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        X_array = np.array([[0.4,0.2,0.4],\n",
    "                            [0.3,0.4,0.5],\n",
    "                            [0.3,-0.4,0.5]])        #建立X_array\n",
    "        (_b,_W,_X,_y) = sess.run((b,W,X,y),feed_dict={X:X_array})\n",
    "        print('b:');print(_b)\n",
    "        print('W:');print(_W)\n",
    "        print('X:');print(_X)\n",
    "        print('y:');print(_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-1.3363371  -0.01283835]]\n",
      "W:\n",
      "[[ 1.8546469   3.108467  ]\n",
      " [ 0.77843046  1.991848  ]\n",
      " [ 0.06419073 -0.5634582 ]]\n",
      "X:\n",
      "[[ 0.4  0.2  0.4]\n",
      " [ 0.3  0.4  0.5]\n",
      " [ 0.3 -0.4  0.5]]\n",
      "y:\n",
      "[[0.        1.4035349]\n",
      " [0.        1.4347119]\n",
      " [0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "placeholder_input_3x3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 创建layer函数以矩阵运算仿真神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_dim:输出的神经元数量\n",
    "#input_dim:输入的神经元数量\n",
    "#inputs:输入的二维数组的placeholder。\n",
    "#activation:传入激活函数，默认是None\n",
    "def layer(output_dim,input_dim,inputs,activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim,output_dim])) #以正态分布的随机数建立并且初始化W（权重）\n",
    "    b = tf.Variable(tf.random_normal([1,output_dim]))\n",
    "    XWb = tf.matmul(inputs,W)+b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用layer函数建立3层类神经网络\n",
    "def run_layer():\n",
    "    X = tf.placeholder(\"float\",[None,4])\n",
    "    h = layer(output_dim=3,input_dim=4,inputs=X,activation=tf.nn.relu)\n",
    "    y = layer(output_dim=2,input_dim=3,inputs=h)\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        X_array = np.array([[0.4,0.2,0.4,0.5]])\n",
    "        (layer_X,layer_h,layer_y) = sess.run((X,h,y),feed_dict={X:X_array})\n",
    "        print('input Layer X:');print(layer_X)\n",
    "        print('hidden Layer h:');print(layer_h)\n",
    "        print('output Layer y:');print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "hidden Layer h:\n",
      "[[0.9396633 0.9441411 1.9303684]]\n",
      "output Layer y:\n",
      "[[ 5.5895567 -2.3082125]]\n"
     ]
    }
   ],
   "source": [
    "run_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 建立layer_debug函数显示权重与偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#创建layer_debug函数\n",
    "def layer_debug(output_dim,input_dim,inputs,activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim,output_dim])) #以正态分布的随机数建立并且初始化W（权重）\n",
    "    b = tf.Variable(tf.random_normal([1,output_dim]))\n",
    "    XWb = tf.matmul(inputs,W)+b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs,W,b                #除了返回output外，还返回W与b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用layer_debug函数建立3层类神经网络\n",
    "def run_layer_debug():\n",
    "    X = tf.placeholder(\"float\",[None,4])\n",
    "    h,W1,b1 = layer_debug(output_dim=3,input_dim=4,inputs=X,activation=tf.nn.relu)\n",
    "    y,W2,b2 = layer_debug(output_dim=2,input_dim=3,inputs=h)\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        X_array = np.array([[0.4,0.2,0.4,0.5]])\n",
    "        (layer_X,layer_h,layer_y) = sess.run((X,h,y),feed_dict={X:X_array})\n",
    "        print('input Layer X:');print(layer_X)\n",
    "        print('W1:');print(sess.run(W1))\n",
    "        print('b1:');print(sess.run(b1))\n",
    "        print('hidden Layer h:');print(layer_h)\n",
    "        print('W2:');print(sess.run(W2))\n",
    "        print('b2:');print(sess.run(b2))\n",
    "        print('output Layer y:');print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "W1:\n",
      "[[-0.12246605 -0.8792767  -0.8470579 ]\n",
      " [ 0.15776376  0.8298426  -0.6541916 ]\n",
      " [-0.05891227  1.4518098   1.1658016 ]\n",
      " [-0.49439707  0.7262468   0.00315505]]\n",
      "b1:\n",
      "[[-1.5122991 -1.4589502 -2.176677 ]]\n",
      "hidden Layer h:\n",
      "[[0. 0. 0.]]\n",
      "W2:\n",
      "[[-0.03432563  1.4983974 ]\n",
      " [ 0.9834229   0.7112851 ]\n",
      " [ 0.27180567  1.6863292 ]]\n",
      "b2:\n",
      "[[-0.06900068  2.069059  ]]\n",
      "output Layer y:\n",
      "[[-0.06900068  2.069059  ]]\n"
     ]
    }
   ],
   "source": [
    "run_layer_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
